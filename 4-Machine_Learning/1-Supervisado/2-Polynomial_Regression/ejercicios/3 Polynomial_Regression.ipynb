{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lObjyER4X6p"
   },
   "source": [
    "## Polynomial Regression on Boston Housing Dataset\n",
    "\n",
    "**In this notebook we do a comparative study of Linear Regression and Polynomial Regression accuracy on the Boston Housing Dataset**\n",
    "\n",
    "This data was originally a part of UCI Machine Learning Repository and has been removed now. This data also ships with the scikit-learn library. \n",
    "There are 506 samples and 13 feature variables in this data-set. The objective is to predict the value of prices of the house using the given features.\n",
    "\n",
    "The description of all the features is given below:\n",
    "\n",
    "  **CRIM**: Per capita crime rate by town\n",
    "\n",
    "  **ZN**: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "\n",
    "  **INDUS**: Proportion of non-retail business acres per town\n",
    "\n",
    "  **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "  **NOX**: Nitric oxide concentration (parts per 10 million)\n",
    "\n",
    "  **RM**: Average number of rooms per dwelling\n",
    "\n",
    "  **AGE**: Proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "  **DIS**: Weighted distances to five Boston employment centers\n",
    "\n",
    "  **RAD**: Index of accessibility to radial highways\n",
    "\n",
    "  **TAX**: Full-value property tax rate per $10,000\n",
    "\n",
    "  **B**: 1000(Bk - 0.63)Â², where Bk is the proportion of [people of African American descent] by town\n",
    "\n",
    "  **LSTAT**: Percentage of lower status of the population\n",
    "\n",
    "  **MEDV**: Median value of owner-occupied homes in $1000s\n",
    "  \n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gorjhNWk1jYI"
   },
   "source": [
    "I**mport the required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICB6ibhd1oo6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZluhUmFzgwN"
   },
   "source": [
    "**Load the Boston Housing DataSet from scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GgjfA1CJ19_K",
    "outputId": "e2caf803-5941-4983-a1b5-dbb3861b75f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boston_dataset is a dictionary. let's check what it contains**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-egcQr3zrr0"
   },
   "source": [
    "**Load the data into pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVlhiwrEz0CQ"
   },
   "source": [
    "**The target values is missing from the data. Create a new column of target values and add it to dataframe in a column called MEDV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G01Hoq3g0BDp"
   },
   "source": [
    "**Data preprocessing**\n",
    "\n",
    "Check for missing values in all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inz3dJr00K6y"
   },
   "source": [
    "**Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IBNTU5N0RQ5"
   },
   "source": [
    "**Correlation matrix**\n",
    "\n",
    "Analyze the correlation matrix. Plot a heatmap\n",
    "\n",
    "* From correlation plot: which are the columns that are more correlated with **MEDV**\n",
    "* There are two features highly correlated. Identify them and drop one of them in order to avoid multi-colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw 2 scatter plots to see the relationship between **MEDV** and **LSTAT** and **RM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Vbf0Z3u-vgb"
   },
   "source": [
    "**Prepare the data for training**\n",
    "Create a dataframe X including **LSTAT** and **RM** columns.\n",
    "Y should be a pandas series including target values **'MEDV'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qloWQhqb0fud"
   },
   "source": [
    "**Split the data into training and testing sets**\n",
    "\n",
    "Splits the training and test data set in 80% : 20%. Assign random_state to any value. This ensures consistency. Print the sahes of the resulting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JSBuka3Eecm"
   },
   "source": [
    "# **Linear Regression**\n",
    "\n",
    "Build a linear regression model with sklearn LinearRegression.\n",
    "We'll use Mean Squared error and R2 score to evaluate our model, so be sure to make the needed imports.\n",
    "\n",
    "Import the necessary functions and train a LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model performance in the training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets see the model performance visually. Let's plot y_test vs y_pred**\n",
    "\n",
    "Plotting the y_test vs y_pred. Ideally should have been a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJuZfJHwfhfa"
   },
   "source": [
    "# **Polynomial Regression**\n",
    "\n",
    "We can see that **LSTAT** doesn't vary exactly in a linear way. Let's apply the Polynomial Regression with **degree 2** and test. \n",
    "\n",
    "To generate the higher order degrees, we use PolyniomialFeatures class from sklearn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5wzgDBShTUh"
   },
   "source": [
    "**Did the model improve using the Polynomial model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Polynomial Regression on Boston Housing Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "7c77fdb427e7cbc9bc1367dd530fc2b36aacdbbde1ac83c85833b10dfa8b831c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
